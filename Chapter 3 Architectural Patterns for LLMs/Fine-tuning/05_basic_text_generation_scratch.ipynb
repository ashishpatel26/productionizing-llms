{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf86620-07de-4067-a147-272285157c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab214ee7-d66a-485b-8074-8172a4cf3dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation\n",
    "# You'll need a large corpus of text data for training\n",
    "corpus = [\n",
    "    'The cat sat on the mat',\n",
    "    'The dog ate my homework',\n",
    "    'I love deep learning',\n",
    "    # Add more text data here...\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce134c-1db0-4f10-806a-4e89f90be2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Text Preprocessing\n",
    "def preprocess_text(corpus):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = tf.keras.utils.to_categorical(label, num_classes=total_words)\n",
    "\n",
    "    return predictors, label, total_words, max_sequence_len, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6207f0-b49d-49fd-a491-acfc3ec9a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors, label, total_words, max_sequence_len, tokenizer = preprocess_text(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15795ceb-e38e-4b66-acf3-0e8334872166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the Model\n",
    "def create_model(total_words, max_sequence_len):\n",
    "    embedding_dim = 100\n",
    "    num_heads = 2\n",
    "    ff_dim = 64\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(max_sequence_len-1,))\n",
    "    embedding_layer = tf.keras.layers.Embedding(total_words, embedding_dim)(inputs)\n",
    "\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(embedding_layer, embedding_layer)\n",
    "    attention_output = tf.keras.layers.Dropout(0.1)(attention_output)\n",
    "    attention_output = tf.keras.layers.Add()([embedding_layer, attention_output])\n",
    "    attention_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "\n",
    "    lstm_output = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150, return_sequences=True))(attention_output)\n",
    "    lstm_output = tf.keras.layers.Dropout(0.2)(lstm_output)\n",
    "\n",
    "    flatten = tf.keras.layers.Flatten()(lstm_output)\n",
    "    dense_layer = tf.keras.layers.Dense(ff_dim, activation='relu')(flatten)\n",
    "    output_layer = tf.keras.layers.Dense(total_words, activation='softmax')(dense_layer)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=output_layer)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51039327-17ff-48d9-8788-0d2273772315",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(total_words, max_sequence_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e2de3-f6e4-49f2-ba18-e730b9e716be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train the Model\n",
    "history = model.fit(predictors, label, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b5db66-59b8-411f-a970-8c488ed6be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate Text\n",
    "def generate_text(seed_text, next_words, max_sequence_len, model, tokenizer):\n",
    "    generated_text = seed_text\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "\n",
    "        # Sample the word index from the predicted probabilities\n",
    "        predicted_index = np.random.choice(len(predicted_probs), p=predicted_probs)\n",
    "\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "        generated_text += \" \" + output_word\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f12cf0-4a8e-4f24-8577-c6a632f836dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "seed_text = \"cat\"\n",
    "generated_text = generate_text(seed_text, 5, max_sequence_len, model, tokenizer)\n",
    "print(f\"Generated Text: {generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0cafd7-ea94-4e06-92bd-268e4597cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "seed_text = \"make\"\n",
    "generated_text = generate_text(seed_text, 5, max_sequence_len, model, tokenizer)\n",
    "print(f\"Generated Text: {generated_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
